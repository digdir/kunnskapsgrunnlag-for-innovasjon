{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n",
    "from src.embedding_model import embed\n",
    "from src.utils import (\n",
    "    populate_concerned_year,\n",
    "    populate_everything,\n",
    "    return_paragraphs_with_highest_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"questions.json\", \"r\") as f:\n",
    "    questions = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df: pd.DataFrame = pd.read_pickle(\"df_with_embeddings_float32_filtered50.pkl\")\n",
    "populate_concerned_year(df)\n",
    "\n",
    "# filtering only years 2022\n",
    "df = df[df[\"concerned_year\"] == 2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"questions_with_embeddings.pkl\", \"rb\") as f:\n",
    "    questions_embedding = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1.1 already answered, skipping...\n",
      "Question 1.2 already answered, skipping...\n",
      "Question 1.3 already answered, skipping...\n",
      "Question 1.4 already answered, skipping...\n",
      "Question 1.5 already answered, skipping...\n",
      "Question 1.6 already answered, skipping...\n",
      "Question 2.1 already answered, skipping...\n",
      "Question 2.2 already answered, skipping...\n",
      "Question 2.3 already answered, skipping...\n",
      "Question 2.4 already answered, skipping...\n",
      "Executing code for question 3.1...\n",
      "Reference texts for question 3.1 already present, skipping...\n",
      "Embedding reference texts...\n",
      "Comparing similarity...\n",
      "Retrieved texts for question 3.1 already present, skipping...\n",
      "Getting final answer from LLM for question:\n",
      "Er det en sammenheng mellom virksomhetene som omtaler digitalisering og digital transformasjon nivået på innovasjonsaktivitet? Altså, er det en korrelasjon mellom virksomheter som er innovative og som er langt fremme med digitalisering?\n",
      "Executing code for question 3.2...\n",
      "Reference texts for question 3.2 already present, skipping...\n",
      "Embedding reference texts...\n",
      "Comparing similarity...\n",
      "Getting final answer from LLM for question:\n",
      "Hvilken type omtale er det i rapportene vedr. spesifikke transformativ teknologi valg som skytjenester, sensor teknologi, kunstig intelligens og/eller annen teknologi?\n",
      "Executing code for question 3.3...\n",
      "Reference texts for question 3.3 already present, skipping...\n",
      "Embedding reference texts...\n",
      "Comparing similarity...\n",
      "Getting final answer from LLM for question:\n",
      "Hvilke virksomheter omtaler spesifikke transformativ teknologi valg som skytjenester, sensor teknologi, kunstig intelligens og/eller annen teknologi?\n",
      "Executing code for question 3.4...\n",
      "Reference texts for question 3.4 already present, skipping...\n",
      "Embedding reference texts...\n",
      "Comparing similarity...\n",
      "Getting final answer from LLM for question:\n",
      "Hvor ofte omtales datadeling, åpne data og lignende i forbindelse med innovasjon?\n",
      "Executing code for question 4.1...\n",
      "Reference texts for question 4.1 already present, skipping...\n",
      "Embedding reference texts...\n",
      "Comparing similarity...\n",
      "Getting final answer from LLM for question:\n",
      "Hvordan jobber virksomhetene med kompetanseutvikling innen digitalisering og nye måter å jobbe på (f.eks. smidig, fremsyn, design, digital)?\n",
      "Executing code for question 4.2...\n",
      "Reference texts for question 4.2 already present, skipping...\n",
      "Embedding reference texts...\n",
      "Comparing similarity...\n",
      "Getting final answer from LLM for question:\n",
      "Hvor mye omtales smidig organisering og smidige prosjekter?\n",
      "Executing code for question 4.3...\n",
      "Reference texts for question 4.3 already present, skipping...\n",
      "Embedding reference texts...\n",
      "Comparing similarity...\n",
      "Getting final answer from LLM for question:\n",
      "Omhandles ledelse som en faktor for å legge til rette for innovasjon?\n",
      "Executing code for question 4.4...\n",
      "Reference texts for question 4.4 already present, skipping...\n",
      "Embedding reference texts...\n",
      "Comparing similarity...\n",
      "Getting final answer from LLM for question:\n",
      "Hva slags type innovasjonsmetoder/caser er mest forekommende?\n",
      "Executing code for question 4.5...\n",
      "Reference texts for question 4.5 already present, skipping...\n",
      "Embedding reference texts...\n",
      "Comparing similarity...\n",
      "Getting final answer from LLM for question:\n",
      "Involveres brukere/innbyggere i tjenesteutviklingen? \n",
      "Executing code for question 5.1...\n",
      "Reference texts for question 5.1 already present, skipping...\n",
      "Embedding reference texts...\n",
      "Comparing similarity...\n",
      "Getting final answer from LLM for question:\n",
      "Hvordan nevnes innovative anskaffelser nevnes i tildelingsbrev og årsrapporter?\n",
      "Executing code for question 5.2...\n",
      "Reference texts for question 5.2 already present, skipping...\n",
      "Embedding reference texts...\n",
      "Comparing similarity...\n",
      "Getting final answer from LLM for question:\n",
      "Hvordan omtales innovative anskaffelser i de virksomhetene som har innovative anskaffelser i sitt tildelingsbrev og som i årsrapport skriver at de har gjort/gjennomført noe\n",
      "Executing code for question 5.3...\n",
      "Reference texts for question 5.3 already present, skipping...\n",
      "Embedding reference texts...\n",
      "Comparing similarity...\n",
      "Getting final answer from LLM for question:\n",
      "I hvilken grad det er offentlig-privat samarbeid som nevnes i tildelingsbrev?\n",
      "Executing code for question 5.4...\n",
      "Reference texts for question 5.4 already present, skipping...\n",
      "Embedding reference texts...\n",
      "Comparing similarity...\n",
      "Getting final answer from LLM for question:\n",
      "Hvordan omtales strategisk bruk av anskaffelser (i tildelingsbrev og årsrapport)\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "model = \"gpt-4-turbo\"\n",
    "examples_to_retrieve = 15\n",
    "for x, y in questions.items():\n",
    "    if (\n",
    "        (len(questions[x][\"reference_texts\"]) != 0)\n",
    "        and (len(questions[x][\"retrieved_texts\"]) != 0)\n",
    "        and (len(questions[x][\"final_answer\"]) != 0)\n",
    "    ):\n",
    "        print(f\"Question {x} already answered, skipping...\")\n",
    "        continue\n",
    "    print(f\"Executing code for question {x}...\")\n",
    "    question_reference = y[\"question_reference\"]\n",
    "    question_final = y[\"question_final\"]\n",
    "    if len(questions[x][\"reference_texts\"]) != 0:\n",
    "        print(f\"Reference texts for question {x} already present, skipping...\")\n",
    "        inn_texts = y[\"reference_texts\"]\n",
    "    else:\n",
    "        print(f\"Getting reference texts from LLM for question:\\n{\n",
    "              question_reference}\")\n",
    "        completion = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"Jeg har en embedding-database med tekster fra offentlige dokumenter, og brukeren stiller spørsmål om tekstene i databasen. Gitt brukerens spørsmål, lag fem referansetekster som kan brukes som kan embeddes og sammenlignes med embeddingene i databasen med cosine-likhet for å finne tekster som kan brukes for å svare på brukerens spørsmål. Tekstene du lager skal være av varierende lengde slik at det fanger opp stikkordet som sees etter, i tillegg til noen lengre tekster som reflekterer ordlyden i tekstene som kan hjelpe å besvare spørsmålene. Pass på at tekstene er relativt ulike hverandre, slik at man kan ta gjennomsnittet av embeddingene for å fange opp essensen. Referansetekstene du lager skal ikke svare på spørsmålet til brukeren, men brukes for å finne tekster i databasen som ligner på tekster som kan besvare brukeren. Svaret ditt skal kun være en python liste, uten forklarende tekst\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"{question_reference}\",\n",
    "                },\n",
    "            ],\n",
    "        )\n",
    "        inn_texts = eval(completion.choices[0].message.content)\n",
    "        y[\"reference_texts\"] = inn_texts\n",
    "    print(\"Embedding reference texts...\")\n",
    "    # inn_texts_embeddings = [embed(inn_text) for inn_text in inn_texts]\n",
    "    # inn_texts_embeddings = np.array(inn_texts_embeddings)\n",
    "    # inn_texts_embedding = np.mean(inn_texts_embeddings, axis=0)\n",
    "    inn_texts_embedding = questions_embedding[x][\"reference_embedding\"]\n",
    "    print(\"Comparing similarity...\")\n",
    "    # else include a series of true with the same length as the dataframe\n",
    "    include_years = (\n",
    "        df[\"type\"] == \"Årsrapport\" if y[\"year_reps\"] else np.array([\n",
    "                                                                   False] * len(df))\n",
    "    )\n",
    "    include_grants = (\n",
    "        df[\"type\"] == \"Tildelingsbrev\" if y[\"grants\"] else np.array([\n",
    "                                                                    False] * len(df))\n",
    "    )\n",
    "    filtered_df = populate_everything(\n",
    "        df[(include_years) | (include_grants)].copy(), inn_texts_embedding\n",
    "    )\n",
    "    if len(questions[x][\"retrieved_texts\"]) != 0:\n",
    "        print(f\"Retrieved texts for question {x} already present, skipping...\")\n",
    "        retrieved_texts = \"\\n\\n\".join(y[\"retrieved_texts\"])\n",
    "    else:\n",
    "        retrieved_texts = return_paragraphs_with_highest_score(\n",
    "            filtered_df, \"deviation_scaled_with_length\", examples_to_retrieve\n",
    "        )\n",
    "        y[\"retrieved_texts\"] = retrieved_texts.strip().split(\"\\n\\n\")\n",
    "    if len(questions[x][\"final_answer\"]) != 0:\n",
    "        print(f\"Final answer for question {x} already present, skipping...\")\n",
    "    else:\n",
    "        print(f\"Getting final answer from LLM for question:\\n{question_final}\")\n",
    "        completion = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": f\"Basert på et sett med teksnutter fra rapporter fra ulike statlige virksomheter som brukeren gir vil jeg at du skal svare på spørsmålet: {question_final}. Pass på at du svarer med grunnlag i tekstsnuttene som brukeren gir, og at du svarer på spørsmålet oppgitt tidligere.\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"{retrieved_texts}\",\n",
    "                },\n",
    "            ],\n",
    "        )\n",
    "        y[\"final_answer\"] = completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"answered_questions.json\", \"w\") as f:\n",
    "    json.dump(questions, f, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
